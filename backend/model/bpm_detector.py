"""
BPM Detector & Click Track Generator - Model Layer

Detecta o BPM da m√∫sica e gera um click track sincronizado.
Vers√£o calibrada para melhor sincroniza√ß√£o.
"""
import logging
from pathlib import Path
from typing import Tuple, Optional
import numpy as np
import soundfile as sf

logger = logging.getLogger(__name__)


class BPMDetector:
    """
    Detecta o BPM (batidas por minuto) de um arquivo de √°udio
    e gera um click track sincronizado usando detec√ß√£o de onsets.
    """
    
    def __init__(self, click_frequency: float = 1000, click_duration: float = 0.03):
        """
        Args:
            click_frequency: Frequ√™ncia do som do click em Hz (padr√£o: 1000Hz)
            click_duration: Dura√ß√£o de cada click em segundos (padr√£o: 30ms)
        """
        self.click_frequency = click_frequency
        self.click_duration = click_duration
    
    def detect_bpm(self, audio_path: Path) -> Tuple[float, np.ndarray]:
        """
        Detecta o BPM e os tempos dos beats no √°udio.
        Usa algoritmo de beat tracking com par√¢metros calibrados.
        
        Args:
            audio_path: Caminho para o arquivo de √°udio
            
        Returns:
            Tuple[bpm, beat_times]: BPM estimado e array com tempos dos beats
        """
        try:
            import librosa
            
            logger.info(f"Detectando BPM de {audio_path}")
            print(f"üéµ Detectando BPM de {audio_path.name}...")
            
            # Carregar √°udio
            y, sr = librosa.load(str(audio_path), sr=22050, mono=True)
            
            # Detec√ß√£o de onset para melhor precis√£o
            onset_env = librosa.onset.onset_strength(
                y=y, 
                sr=sr,
                hop_length=512,
                aggregate=np.median  # Mais robusto a ru√≠do
            )
            
            # Detectar tempo (BPM) e beats com par√¢metros calibrados
            tempo, beat_frames = librosa.beat.beat_track(
                y=y, 
                sr=sr,
                onset_envelope=onset_env,
                hop_length=512,
                start_bpm=120,      # BPM inicial t√≠pico
                tightness=100,       # Maior precis√£o na sincroniza√ß√£o
                trim=True            # Remove beats imprecisos do in√≠cio/fim
            )
            
            # Converter frames para tempo em segundos
            beat_times = librosa.frames_to_time(beat_frames, sr=sr, hop_length=512)
            
            # Arredondar BPM para valor mais pr√≥ximo
            bpm = float(round(tempo[0] if hasattr(tempo, '__iter__') else tempo))
            
            # Validar BPM (deve estar entre 60-200 para m√∫sica popular)
            if bpm < 60:
                bpm = bpm * 2  # Provavelmente detectou metade do tempo
            elif bpm > 200:
                bpm = bpm / 2  # Provavelmente detectou dobro do tempo
            
            logger.info(f"BPM detectado: {bpm} ({len(beat_times)} beats)")
            print(f"‚úÖ BPM detectado: {bpm} ({len(beat_times)} beats)")
            
            return bpm, beat_times
            
        except Exception as e:
            logger.exception("Erro ao detectar BPM")
            print(f"‚ùå Erro ao detectar BPM: {str(e)}")
            # Retornar BPM padr√£o (120) se falhar
            return 120.0, np.array([])
    
    def refine_beat_times(self, y: np.ndarray, sr: int, beat_times: np.ndarray) -> np.ndarray:
        """
        Refina os tempos dos beats usando detec√ß√£o de onset local.
        Ajusta cada beat para o onset mais pr√≥ximo.
        """
        import librosa
        
        # Detectar todos os onsets
        onset_frames = librosa.onset.onset_detect(y=y, sr=sr, hop_length=512)
        onset_times = librosa.frames_to_time(onset_frames, sr=sr, hop_length=512)
        
        if len(onset_times) == 0:
            return beat_times
        
        refined_times = []
        window = 0.05  # 50ms de janela para ajuste
        
        for beat_time in beat_times:
            # Encontrar onset mais pr√≥ximo dentro da janela
            nearby = onset_times[np.abs(onset_times - beat_time) < window]
            if len(nearby) > 0:
                # Usar o onset mais pr√≥ximo
                closest = nearby[np.argmin(np.abs(nearby - beat_time))]
                refined_times.append(closest)
            else:
                refined_times.append(beat_time)
        
        return np.array(refined_times)
    
    def generate_click_track(
        self, 
        audio_path: Path, 
        output_path: Path,
        bpm: Optional[float] = None,
        beat_times: Optional[np.ndarray] = None
    ) -> Tuple[str, float]:
        """
        Gera um click track sincronizado com o √°udio original.
        Usa beats detectados e refinados para m√°xima precis√£o.
        
        Args:
            audio_path: Caminho do √°udio original (para obter dura√ß√£o)
            output_path: Caminho para salvar o click track
            bpm: BPM (se j√° detectado)
            beat_times: Tempos dos beats (se j√° detectados)
            
        Returns:
            Tuple[path, bpm]: Caminho do arquivo gerado e BPM
        """
        try:
            import librosa
            
            # Carregar √°udio original
            y_original, sr_original = librosa.load(str(audio_path), sr=22050, mono=True)
            duration = len(y_original) / sr_original
            
            # Detectar BPM se n√£o fornecido
            if bpm is None or beat_times is None or len(beat_times) == 0:
                bpm, beat_times = self.detect_bpm(audio_path)
            
            # Refinar tempos dos beats
            if len(beat_times) > 0:
                beat_times = self.refine_beat_times(y_original, sr_original, beat_times)
            
            # Se n√£o conseguiu detectar beats, gerar baseado no BPM
            if len(beat_times) == 0:
                beat_interval = 60.0 / bpm
                # Detectar primeiro onset como ponto de partida
                onset_frames = librosa.onset.onset_detect(y=y_original, sr=sr_original)
                if len(onset_frames) > 0:
                    start_time = librosa.frames_to_time(onset_frames[0], sr=sr_original)
                else:
                    start_time = 0
                beat_times = np.arange(start_time, duration, beat_interval)
            
            # Sample rate para o click track (igual ao stem do Demucs)
            sr = 44100
            
            # Criar array de sil√™ncio com a mesma dura√ß√£o
            click_track = np.zeros(int(duration * sr))
            
            # Gerar forma de onda do click (mais curto e preciso)
            click_samples = int(self.click_duration * sr)
            t = np.linspace(0, self.click_duration, click_samples)
            
            # Envelope de decaimento r√°pido
            envelope = np.exp(-t * 50)
            
            # Click principal (downbeat) - mais grave e mais alto
            click_main = np.sin(2 * np.pi * 900 * t) * envelope * 0.9
            
            # Click secund√°rio (upbeat) - mais agudo e mais suave
            click_sub = np.sin(2 * np.pi * 1400 * t) * envelope * 0.5
            
            # Determinar compasso (4/4 √© mais comum)
            # O primeiro beat detectado √© considerado o downbeat
            
            # Inserir clicks nos tempos detectados
            for i, beat_time in enumerate(beat_times):
                sample_pos = int(beat_time * sr)
                
                # Alternar entre click principal (a cada 4 beats) e secund√°rio
                click = click_main if i % 4 == 0 else click_sub
                
                # Inserir click
                end_pos = min(sample_pos + len(click), len(click_track))
                insert_len = end_pos - sample_pos
                
                if insert_len > 0 and sample_pos >= 0:
                    click_track[sample_pos:end_pos] += click[:insert_len]
            
            # Normalizar
            max_val = np.max(np.abs(click_track))
            if max_val > 0:
                click_track = click_track / max_val * 0.8
            
            # Converter para stereo
            click_track_stereo = np.column_stack([click_track, click_track])
            
            # Salvar como WAV
            output_path.parent.mkdir(parents=True, exist_ok=True)
            sf.write(str(output_path), click_track_stereo, sr)
            
            logger.info(f"Click track gerado: {output_path} (BPM: {bpm})")
            print(f"ü•Å Click track gerado: {output_path.name} (BPM: {bpm}, {len(beat_times)} beats)")
            
            return str(output_path), bpm
            
        except Exception as e:
            logger.exception("Erro ao gerar click track")
            print(f"‚ùå Erro ao gerar click track: {str(e)}")
            raise


# Inst√¢ncia global para uso
bpm_detector = BPMDetector(
    click_frequency=1000,
    click_duration=0.03  # Click mais curto para melhor precis√£o
)
